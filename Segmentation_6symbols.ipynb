{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to pyiunstir!\n",
    "\n",
    "\n",
    "This is a model to identify different words in iberian 6-symbol fragments\n",
    "\n",
    "Exaple: \"teitataŕeseŕaśoankeibonatintaneśte\" should be read as \"deitataŕes eŕaśoan geibon adintaneśde\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pyiunstir.encoding import *\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "f_json = open('corpus/iberian.json', 'r')\n",
    "symbols = json.load(f_json)\n",
    "f_json.close()\n",
    "\n",
    "f_json = open('corpus/NE_database.json', 'r')\n",
    "corpus_NE = json.load(f_json)\n",
    "f_json.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the NE corpus and remove the scriptio continua being used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2883"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for instance in corpus_NE:\n",
    "    line = instance['text']\n",
    "    # Remove the validation example from the training set\n",
    "    if instance['text_simplified'][0].find('teitata') == 0:\n",
    "        continue\n",
    "    for row in line:\n",
    "        word = []\n",
    "        for w in row:\n",
    "            symbol = ' '\n",
    "            for csymbol in symbols:\n",
    "                if w == csymbol['id']:\n",
    "                    symbol = csymbol['simplified']\n",
    "                    word.append(symbol)\n",
    "                    break\n",
    "        words.append(word)\n",
    "\n",
    "symbol_set = list(set(list(itertools.chain.from_iterable(words))))\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder = labelencoder.fit(symbol_set)\n",
    "\n",
    "        \n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the training set of sequence for the segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "n1 = 0\n",
    "for w0 in words:\n",
    " #print(len(w0))\n",
    " for c1 in range(len(w0)):\n",
    "    c2 = c1+7\n",
    "    frag =w0[c1:c2]\n",
    "    if len(frag) == 7:\n",
    "        n1 += 1\n",
    "        label = 0\n",
    "        if frag[3] == ':':\n",
    "            label = 1\n",
    "        vect = []\n",
    "        for n in range(len(frag)):\n",
    "            if n == 3:\n",
    "                continue\n",
    "            c = frag[n]\n",
    "            vect.append(labelencoder.transform([c])[0])\n",
    "        X.append(vect)\n",
    "        y.append(label)\n",
    "        #print(frag,label, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9894"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 8591, 1: 1303})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RandomForestClassifier()\n",
    "m.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model with the scriptio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq_ib = break_syl('teitataŕeseŕaśoankeibonatintaneśte')\n",
    "#tq_ib = break_syl('sŕkoanetabebentosutanbirtebitu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['te', 'i', 'ta', 'ta', 'ŕ', 'e', 's', 'e', 'ŕ', 'a', 'ś', 'o', 'a', 'n', 'ke', 'i', 'bo', 'n', 'a', 'ti', 'n', 'ta', 'n', 'e', 'ś', 'te']\n",
      "['te', 'i', 'ta', 'ta', 'ŕ', 'e']\n",
      "['i', 'ta', 'ta', 'ŕ', 'e', 's']\n",
      "['ta', 'ta', 'ŕ', 'e', 's', 'e']\n",
      "['ta', 'ŕ', 'e', 's', 'e', 'ŕ']\n",
      "['ŕ', 'e', 's', 'e', 'ŕ', 'a']\n",
      "--> ŕes : eŕa 0.75\n",
      "['e', 's', 'e', 'ŕ', 'a', 'ś']\n",
      "['s', 'e', 'ŕ', 'a', 'ś', 'o']\n",
      "--> seŕ : aśo 0.76\n",
      "['e', 'ŕ', 'a', 'ś', 'o', 'a']\n",
      "['ŕ', 'a', 'ś', 'o', 'a', 'n']\n",
      "--> ŕaś : oan 0.52\n",
      "['a', 'ś', 'o', 'a', 'n', 'ke']\n",
      "['ś', 'o', 'a', 'n', 'ke', 'i']\n",
      "['o', 'a', 'n', 'ke', 'i', 'bo']\n",
      "['a', 'n', 'ke', 'i', 'bo', 'n']\n",
      "['n', 'ke', 'i', 'bo', 'n', 'a']\n",
      "['ke', 'i', 'bo', 'n', 'a', 'ti']\n",
      "['i', 'bo', 'n', 'a', 'ti', 'n']\n",
      "--> ibon : atin 0.59\n",
      "['bo', 'n', 'a', 'ti', 'n', 'ta']\n",
      "['n', 'a', 'ti', 'n', 'ta', 'n']\n",
      "['a', 'ti', 'n', 'ta', 'n', 'e']\n",
      "['ti', 'n', 'ta', 'n', 'e', 'ś']\n",
      "['n', 'ta', 'n', 'e', 'ś', 'te']\n",
      "--> ntan : eśte 0.59\n",
      "==> teitataŕeseŕaśoankeibonatintaneśte\n",
      "--> teitataŕes:eŕ:aś:oankeibon:atintan:eśte\n",
      "..> teitataŕes:eŕaśoan:keibon:atintaneśte\n"
     ]
    }
   ],
   "source": [
    "for w0 in [tq_ib]:\n",
    " if 1 == 1:\n",
    "  print(w0)\n",
    "  w0b = w0\n",
    "  nw = []\n",
    "  wclean= []\n",
    "  for q in w0:\n",
    "    if q == ':':\n",
    "        continue\n",
    "    wclean.append(q)\n",
    "  for c1 in range(len(wclean)):\n",
    "    c2 = c1+6\n",
    "    frag =wclean[c1:c2]\n",
    "    if len(frag) == 6:\n",
    "        print(frag)\n",
    "        vectt = labelencoder.transform(frag).tolist()\n",
    "        t0 = ''.join(frag[0:3])\n",
    "        t1 = ''.join(frag[3:])\n",
    "        prob = m.predict_proba([vectt])[0][1]\n",
    "        if prob > 0.5:\n",
    "            print('-->',  t0,':',t1, prob)\n",
    "            nw.append(c1+3)\n",
    "            \n",
    "  if len(nw) > 0:\n",
    "    final_w = []\n",
    "    for i in range(len(wclean)):\n",
    "        if i in nw:\n",
    "            final_w.append(':')\n",
    "        final_w.append(wclean[i])\n",
    "    print('==>',''.join(w0b))\n",
    "\n",
    "    print('-->',''.join(final_w))\n",
    "print('..> teitataŕes:eŕaśoan:keibon:atintaneśte')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As it can be seen, the segmentation model allows overlapping of cleavage sites even when the resulting word is very unlikely (2 symbols). It also missed a site and removed the ergative ending of the personal name \"Adintanes\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
